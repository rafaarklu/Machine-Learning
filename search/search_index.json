{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupo","title":"Grupo","text":"<ol> <li>Rafael Arkchimor Lucena</li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Machine Learning</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"Machine-Learning/decision_tree_project/","title":"Machine Learning com \u00c1rvore de Decis\u00e3o","text":""},{"location":"Machine-Learning/decision_tree_project/#machine-learning-com-arvore-de-decisao","title":"Machine Learning com \u00c1rvore de Decis\u00e3o","text":""},{"location":"Machine-Learning/decision_tree_project/#tabela-utilizada","title":"Tabela Utilizada","text":"<p>Dataset - Kaggle</p> <p>Utilizaremos a base de dados de carros usados da BMW para prever a categoria de consumo de combust\u00edvel (baixo, m\u00e9dio ou alto) com base nas caracter\u00edsticas do ve\u00edculo.</p>"},{"location":"Machine-Learning/decision_tree_project/#caracteristicas-features-utilizadas","title":"Caracter\u00edsticas (Features) Utilizadas","text":"<ul> <li>Model (modelo)  </li> <li>Year (ano do carro)  </li> <li>Price (pre\u00e7o)  </li> <li>Transmission (tipo de transmiss\u00e3o do carro)  </li> <li>Mileage (quilometragem)  </li> <li>FuelType (tipo de combust\u00edvel)  </li> <li>Tax (imposto)  </li> <li>Engine Size (tamanho do motor)  </li> </ul>"},{"location":"Machine-Learning/decision_tree_project/#variavel-alvo-target","title":"Vari\u00e1vel Alvo (Target)","text":"<p>consumo_cat: Uma categoria (baixo, m\u00e9dio, alto) criada a partir da coluna <code>mpg</code> (Milhas por Gal\u00e3o), que indica a efici\u00eancia de combust\u00edvel.</p>"},{"location":"Machine-Learning/decision_tree_project/#modelo-arvore-de-decisao-decision-tree","title":"Modelo \u00c1rvore de Decis\u00e3o (Decision Tree)","text":"outputcode <p>Accuracy: 0.97  2025-10-01T17:06:56.862514 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\n\nimport kagglehub\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\nplt.figure(figsize=(12, 10))\n\n\npath = kagglehub.dataset_download(\"adityadesai13/used-car-dataset-ford-and-mercedes\")\n\ndf = pd.read_csv(path + \"/bmw.csv\")  \nx = df[['model', 'year', 'price', 'transmission', 'mileage', 'fuelType', 'tax', 'engineSize']]\n\nlabel_encoder = LabelEncoder()\n\n\n\n# Carregar o conjunto de dados\nlabel_encoder = LabelEncoder()\nx['model'] = label_encoder.fit_transform(x['model'])\nx['transmission'] = label_encoder.fit_transform(x['transmission'])\nx['fuelType'] = label_encoder.fit_transform(x['fuelType'])  \n\n#setar a saida\ny= df['consumo_cat'] = pd.cut(\n        df['mpg'],\n        bins=[0, 25, 40, 100],   # faixas (ajust\u00e1veis)\n        labels=['baixo', 'medio', 'alto']\n)\n\n\n\n\ndata = x.copy()\ndata['target'] = y\n\n# Deletar linhas com valores ausentes\ndata = data.dropna()\n\n# Dividir em caracter\u00edsticas (X) e alvo (y)\nx_clean = data.drop('target', axis=1)\ny_clean = data['target']\n\n# Treinar e testar o modelo\nx_train, x_test, y_train, y_test = train_test_split(\n    x_clean, y_clean, \n    test_size=0.7, \n    random_state=42\n)\n\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\n# Avaliar o modelo\naccuracy = classifier.score(x_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\ntree.plot_tree(classifier)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"Machine-Learning/decision_tree_project/#passo-a-passo","title":"Passo a Passo","text":""},{"location":"Machine-Learning/decision_tree_project/#1-baixar-e-importar-bibliotecas","title":"1. Baixar e importar bibliotecas","text":"<pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nimport kagglehub\n\nplt.figure(figsize=(12, 10))\n</code></pre> <p>Explica\u00e7\u00e3o: Aqui importamos as bibliotecas necess\u00e1rias: - <code>pandas</code> para manipula\u00e7\u00e3o de dados, - <code>matplotlib</code> para visualiza\u00e7\u00e3o, - <code>scikit-learn</code> (<code>tree</code>, <code>train_test_split</code>, <code>LabelEncoder</code>, <code>accuracy_score</code>) para o modelo de \u00e1rvore e m\u00e9tricas, - <code>kagglehub</code> para baixar o dataset, - <code>StringIO</code> para salvar e exibir gr\u00e1ficos.  </p>"},{"location":"Machine-Learning/decision_tree_project/#2-carregar-a-base-de-dados","title":"2. Carregar a base de dados","text":"<pre><code>path = kagglehub.dataset_download(\"adityadesai13/used-car-dataset-ford-and-mercedes\")\n\ndf = pd.read_csv(path + \"/bmw.csv\")  \nx = df[['model', 'year', 'price', 'transmission', 'mileage', 'fuelType', 'tax', 'engineSize']]\n</code></pre> <p>Explica\u00e7\u00e3o: O dataset da BMW \u00e9 baixado diretamente do Kaggle e carregado em um DataFrame <code>df</code>. Selecionamos apenas as colunas relevantes que ser\u00e3o usadas como vari\u00e1veis explicativas (features).</p>"},{"location":"Machine-Learning/decision_tree_project/#3-transformar-variaveis-e-criar-a-variavel-alvo","title":"3. Transformar vari\u00e1veis e criar a vari\u00e1vel alvo","text":"<pre><code>label_encoder = LabelEncoder()\nx['model'] = label_encoder.fit_transform(x['model'])\nx['transmission'] = label_encoder.fit_transform(x['transmission'])\nx['fuelType'] = label_encoder.fit_transform(x['fuelType'])  \n\n# Definir sa\u00edda (Alvo de Classifica\u00e7\u00e3o: Categoria de Consumo)\ny = df['consumo_cat'] = pd.cut(\n        df['mpg'],\n        bins=[0, 25, 40, 100],  \n        labels=['baixo', 'medio', 'alto']\n)\n\ndata = x.copy()\ndata['target'] = y\n</code></pre> <p>Explica\u00e7\u00e3o: As vari\u00e1veis categ\u00f3ricas (<code>model</code>, <code>transmission</code>, <code>fuelType</code>) s\u00e3o convertidas para valores num\u00e9ricos usando <code>LabelEncoder</code>. A vari\u00e1vel alvo (<code>consumo_cat</code>) \u00e9 criada a partir da coluna <code>mpg</code>, categorizando o consumo em baixo, m\u00e9dio e alto. O DataFrame final (<code>data</code>) cont\u00e9m tanto os atributos quanto o target.</p>"},{"location":"Machine-Learning/decision_tree_project/#4-limpar-valores-ausentes","title":"4. Limpar valores ausentes","text":"<pre><code>data = data.dropna()\n\nx_clean = data.drop('target', axis=1)\ny_clean = data['target']\n</code></pre> <p>Explica\u00e7\u00e3o: Aqui removemos valores ausentes (<code>NaN</code>) para garantir a qualidade dos dados. <code>x_clean</code> cont\u00e9m apenas as features e <code>y_clean</code> a vari\u00e1vel alvo (<code>consumo_cat</code>).</p>"},{"location":"Machine-Learning/decision_tree_project/#5-treinar-e-avaliar-o-modelo","title":"5. Treinar e Avaliar o Modelo","text":"<pre><code>x_train, x_test, y_train, y_test = train_test_split(\n    x_clean, y_clean, \n    test_size=0.7, \n    random_state=42\n)\n\n# Criar e treinar o modelo\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\n# Avaliar o modelo\naccuracy = classifier.score(x_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n# Plotar a \u00e1rvore\ntree.plot_tree(classifier)\n\n# Salvar e imprimir para exibi\u00e7\u00e3o (\u00fatil para documenta\u00e7\u00e3o)\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre> <p>Explica\u00e7\u00e3o: 1. Divis\u00e3o da base: <code>train_test_split</code> divide os dados em treino (30%) e teste (70%). 2. Cria\u00e7\u00e3o do modelo: <code>DecisionTreeClassifier</code> \u00e9 instanciado. 3. Treinamento: <code>fit(x_train, y_train)</code> ajusta o modelo aos dados de treino. 4. Avalia\u00e7\u00e3o: <code>score(x_test, y_test)</code> retorna a acur\u00e1cia do modelo. 5. Visualiza\u00e7\u00e3o: <code>tree.plot_tree</code> gera o gr\u00e1fico da \u00e1rvore de decis\u00e3o. 6. Exporta\u00e7\u00e3o: o gr\u00e1fico \u00e9 salvo em formato SVG para uso em documenta\u00e7\u00e3o.</p>"},{"location":"Machine-Learning/decision_tree_project/#resumo","title":"Resumo","text":"<p>O projeto segue as seguintes etapas: 1. Importa\u00e7\u00e3o de bibliotecas, 2. Carregamento da base de dados, 3. Transforma\u00e7\u00e3o e cria\u00e7\u00e3o da vari\u00e1vel alvo, 4. Limpeza de valores ausentes, 5. Treinamento, avalia\u00e7\u00e3o e visualiza\u00e7\u00e3o da \u00e1rvore de decis\u00e3o.  </p> <p>Esse fluxo permite analisar o desempenho do modelo e entender como as vari\u00e1veis influenciam a categoria de consumo de combust\u00edvel.</p> <pre><code>``` python exec=\"off\" \nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport kagglehub\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\nplt.figure(figsize=(12, 10))\n\n\npath = kagglehub.dataset_download(\"adityadesai13/used-car-dataset-ford-and-mercedes\")\n\ndf = pd.read_csv(path + \"/bmw.csv\")  \nx = df[['model', 'year', 'price', 'transmission', 'mileage', 'fuelType', 'tax', 'engineSize']]\n\nlabel_encoder = LabelEncoder()\n\n\n\n# Carregar o conjunto de dados\nlabel_encoder = LabelEncoder()\nx['model'] = label_encoder.fit_transform(x['model'])\nx['transmission'] = label_encoder.fit_transform(x['transmission'])\nx['fuelType'] = label_encoder.fit_transform(x['fuelType'])  \n\n#setar a saida\ny= df['consumo_cat'] = pd.cut(\n        df['mpg'],\n        bins=[0, 25, 40, 100],   # faixas (ajust\u00e1veis)\n        labels=['baixo', 'medio', 'alto']\n)\n\n\n\n\ndata = x.copy()\ndata['target'] = y\n\n# Deletar linhas com valores ausentes\ndata = data.dropna()\n\n# Dividir em caracter\u00edsticas (X) e alvo (y)\nx_clean = data.drop('target', axis=1)\ny_clean = data['target']\n\n# Treinar e testar o modelo\nx_train, x_test, y_train, y_test = train_test_split(\n    x_clean, y_clean, \n    test_size=0.7, \n    random_state=42\n)\n\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\n# Avaliar o modelo\naccuracy = classifier.score(x_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\ntree.plot_tree(classifier)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n\n```\n</code></pre>"},{"location":"Machine-Learning/decision_tree_project/#passo-a-passo_1","title":"Passo a Passo","text":""},{"location":"Machine-Learning/decision_tree_project/#1-baixar-e-importar-bibliotecas_1","title":"1. Baixar e importar bibliotecas","text":"<pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nimport kagglehub\n\nplt.figure(figsize=(12, 10))\n</code></pre>"},{"location":"Machine-Learning/decision_tree_project/#2-carregar-a-base-de-dados_1","title":"2. Carregar a base de dados","text":"<pre><code>path = kagglehub.dataset_download(\"adityadesai13/used-car-dataset-ford-and-mercedes\")\n\ndf = pd.read_csv(path + \"/bmw.csv\")  \nx = df[['model', 'year', 'price', 'transmission', 'mileage', 'fuelType', 'tax', 'engineSize']]\n</code></pre>"},{"location":"Machine-Learning/decision_tree_project/#3-transformar-variaveis-e-criar-a-variavel-alvo_1","title":"3. Transformar vari\u00e1veis e criar a vari\u00e1vel alvo","text":"<pre><code>label_encoder = LabelEncoder()\nx['model'] = label_encoder.fit_transform(x['model'])\nx['transmission'] = label_encoder.fit_transform(x['transmission'])\nx['fuelType'] = label_encoder.fit_transform(x['fuelType'])  \n\n# Definir sa\u00edda (Alvo de Classifica\u00e7\u00e3o: Categoria de Consumo)\ny = df['consumo_cat'] = pd.cut(\n        df['mpg'],\n        bins=[0, 25, 40, 100],  \n        labels=['baixo', 'medio', 'alto']\n)\n\ndata = x.copy()\ndata['target'] = y\n</code></pre>"},{"location":"Machine-Learning/decision_tree_project/#4-limpar-valores-ausentes_1","title":"4. Limpar valores ausentes","text":"<pre><code>data = data.dropna()\n\nx_clean = data.drop('target', axis=1)\ny_clean = data['target']\n</code></pre>"},{"location":"Machine-Learning/decision_tree_project/#5-treinar-e-avaliar-o-modelo_1","title":"5. Treinar e Avaliar o Modelo","text":"<pre><code>x_train, x_test, y_train, y_test = train_test_split(\n    x_clean, y_clean, \n    test_size=0.7, \n    random_state=42\n)\n\n# Criar e treinar o modelo\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\n# Avaliar o modelo\naccuracy = classifier.score(x_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n# Plotar a \u00e1rvore\ntree.plot_tree(classifier)\n\n# Salvar e imprimir para exibi\u00e7\u00e3o (\u00fatil para documenta\u00e7\u00e3o)\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"k-means/main/","title":"K-Means","text":""},{"location":"k-means/main/#documentacao-k-means-clustering-no-titanic","title":"Documenta\u00e7\u00e3o - K-Means Clustering no Titanic","text":"<p>Este script aplica o algoritmo K-Means Clustering ao dataset Titanic, baixado automaticamente do Kaggle via <code>kagglehub</code>. O objetivo \u00e9 agrupar os passageiros com base em caracter\u00edsticas selecionadas e visualizar os clusters.</p> outputcode 2025-10-01T17:06:59.379564 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport kagglehub\nimport os\nfrom io import BytesIO\n\n\n\npath = kagglehub.dataset_download(\"yasserh/titanic-dataset\")\nfile_path = os.path.join(path, \"Titanic-Dataset.csv\")\ndf = pd.read_csv(file_path)\n\n\n\nfeatures = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].copy()\n\nfeatures['Sex'] = LabelEncoder().fit_transform(features['Sex'])\n\nfeatures['Age'].fillna(features['Age'].median(), inplace=True)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(features)\n\nx_var = 'Age'\ny_var = 'Fare'\nx_idx = features.columns.get_loc(x_var)\ny_idx = features.columns.get_loc(y_var)\n\n\nkmeans = KMeans(n_clusters=2, init='k-means++', max_iter=100, random_state=42, n_init=10)\nlabels = kmeans.fit_predict(X_scaled)\n\n\n\nplt.figure(figsize=(10, 8))\n\nplt.scatter(X_scaled[:, x_idx], X_scaled[:, y_idx], c=labels, cmap='viridis', s=50)\nplt.scatter(kmeans.cluster_centers_[:, x_idx], kmeans.cluster_centers_[:, y_idx],\n            c='red', marker='*', s=200, label='Centroids')\n\nplt.title(\"K-Means Clustering - Titanic Dataset\")\nplt.xlabel(f\"{x_var} (scaled)\")\nplt.ylabel(f\"{y_var} (scaled)\")\nplt.legend()\n\n\nbuffer = BytesIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nbuffer.seek(0)\nprint(buffer.getvalue().decode(\"utf-8\"))\n</code></pre>"},{"location":"k-means/main/#documentacao-k-means-clustering-no-titanic_1","title":"Documenta\u00e7\u00e3o - K-Means Clustering no Titanic","text":"<p>Este script aplica o algoritmo K-Means Clustering ao dataset Titanic, baixado automaticamente do Kaggle via <code>kagglehub</code>. O objetivo \u00e9 agrupar os passageiros com base em caracter\u00edsticas selecionadas e visualizar os clusters.</p>"},{"location":"k-means/main/#1-importacao-das-bibliotecas","title":"1. Importa\u00e7\u00e3o das bibliotecas","text":"<ul> <li>pandas: manipula\u00e7\u00e3o de dados.  </li> <li>matplotlib: visualiza\u00e7\u00e3o gr\u00e1fica.  </li> <li>sklearn.cluster.KMeans: algoritmo de agrupamento.  </li> <li>sklearn.preprocessing.StandardScaler, LabelEncoder: pr\u00e9-processamento (normaliza\u00e7\u00e3o e codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas).  </li> <li>kagglehub: download autom\u00e1tico do dataset.  </li> <li>os: manipula\u00e7\u00e3o de caminhos de arquivos.  </li> <li>StringIO: salvar o gr\u00e1fico em formato SVG para exibi\u00e7\u00e3o no MkDocs.</li> </ul>"},{"location":"k-means/main/#2-download-e-carregamento-do-dataset","title":"2. Download e carregamento do dataset","text":"<ol> <li>O dataset Titanic-Dataset.csv \u00e9 baixado do Kaggle atrav\u00e9s do <code>kagglehub</code>.  </li> <li>O arquivo \u00e9 carregado em um DataFrame <code>pandas</code>.</li> </ol> <pre><code>path = kagglehub.dataset_download(\"yasserh/titanic-dataset\")\nfile_path = os.path.join(path, \"Titanic-Dataset.csv\")\ndf = pd.read_csv(file_path)\n</code></pre>"},{"location":"k-means/main/#3-preparacao-dos-dados","title":"3. Prepara\u00e7\u00e3o dos dados","text":"<ul> <li> <p>Sele\u00e7\u00e3o de vari\u00e1veis: Age e Fare.</p> </li> <li> <p>Codifica\u00e7\u00e3o de vari\u00e1vel categ\u00f3rica: Sex convertido para valores num\u00e9ricos (0 ou 1).</p> </li> <li> <p>Tratamento de valores ausentes: valores nulos em Age substitu\u00eddos pela mediana.</p> </li> <li> <p>Normaliza\u00e7\u00e3o: as vari\u00e1veis s\u00e3o escalonadas (StandardScaler) para padronizar a magnitude.</p> </li> </ul> <pre><code>features = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].copy()\nfeatures['Sex'] = LabelEncoder().fit_transform(features['Sex'])\nfeatures['Age'].fillna(features['Age'].median(), inplace=True)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(features)\n</code></pre>"},{"location":"k-means/main/#4-aplicacao-do-k-means","title":"4. Aplica\u00e7\u00e3o do K-Means","text":"<ul> <li> <p>N\u00famero de clusters: 2 (definido manualmente).</p> </li> <li> <p>Inicializa\u00e7\u00e3o: k-means++.</p> </li> <li> <p>M\u00e1ximo de itera\u00e7\u00f5es: 100.</p> </li> <li> <p>Semente aleat\u00f3ria (random_state=42) para reprodutibilidade.</p> </li> <li> <p>Resultado: vetor labels com o cluster de cada passageiro.</p> </li> </ul> <pre><code>kmeans = KMeans(n_clusters=2, init='k-means++', max_iter=100, random_state=42, n_init=10)\nlabels = kmeans.fit_predict(X_scaled)\n</code></pre>"},{"location":"k-means/main/#5-visualizacao-dos-clusters","title":"5. Visualiza\u00e7\u00e3o dos clusters","text":"<ul> <li> <p>Plotagem em 2D com as duas primeiras vari\u00e1veis escalonadas.</p> </li> <li> <p>Passageiros s\u00e3o representados por pontos coloridos conforme o cluster.</p> </li> <li> <p>Centros dos clusters (centroids) destacados em vermelho (*).</p> </li> </ul> <pre><code>plt.figure(figsize=(10, 8))\nplt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis', s=50)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n            c='red', marker='*', s=200, label='Centroids')\nplt.title(\"K-Means Clustering - Titanic Dataset\")\nplt.xlabel(\"Feature 1 (scaled)\")\nplt.ylabel(\"Feature 2 (scaled)\")\nplt.legend()\n</code></pre>"},{"location":"k-means/main/#6-exportacao-do-grafico-para-mkdocs","title":"6. Exporta\u00e7\u00e3o do gr\u00e1fico para MkDocs","text":"<ul> <li> <p>O gr\u00e1fico \u00e9 salvo em formato SVG em mem\u00f3ria (StringIO).</p> </li> <li> <p>O conte\u00fado \u00e9 exibido via print() para integra\u00e7\u00e3o no MkDocs.</p> </li> </ul> <pre><code>from io import StringIO\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"k-nearest-neighbor/knn_documentacao/","title":"Machine Learning com KNN (K-Nearest Neighbors)","text":""},{"location":"k-nearest-neighbor/knn_documentacao/#machine-learning-com-knn-k-nearest-neighbors","title":"Machine Learning com KNN (K-Nearest Neighbors)","text":""},{"location":"k-nearest-neighbor/knn_documentacao/#base-de-dados-utilizada","title":"Base de Dados Utilizada","text":"<p>A base de dados utilizada \u00e9 o conjunto de carros usados da BMW:\\ https://www.kaggle.com/datasets/adityadesai13/used-car-dataset-ford-and-mercedes/data</p>"},{"location":"k-nearest-neighbor/knn_documentacao/#objetivo-do-projeto","title":"Objetivo do Projeto","text":"<p>O objetivo deste trabalho \u00e9 aplicar o algoritmo K-Nearest Neighbors (KNN) para resolver um problema de Classifica\u00e7\u00e3o e prever o Tipo de Combust\u00edvel (fuelType) de um ve\u00edculo.</p> <p>Para simplificar a visualiza\u00e7\u00e3o da fronteira de decis\u00e3o, o modelo utiliza apenas as seguintes features cont\u00ednuas:</p> <ul> <li>Engine Size (Tamanho do Motor)</li> <li>Mileage (Quilometragem/Rodagem)</li> </ul>"},{"location":"k-nearest-neighbor/knn_documentacao/#analise-e-modelo-knn-k3","title":"An\u00e1lise e Modelo KNN (K=3)","text":"<p>O gr\u00e1fico gerado abaixo representa a fronteira de decis\u00e3o do modelo. As regi\u00f5es coloridas indicam a classe (tipo de combust\u00edvel) que o modelo KNN prev\u00ea para qualquer novo carro que caia naquela \u00e1rea do plano 2D.</p> <p>Tipo de Combust\u00edvel   Cor de Classifica\u00e7\u00e3o</p> <p>Diesel                Azul   Petrol                Vermelho/Laranja   Hybrid                Roxo (\u00e1reas menores)</p>"},{"location":"k-nearest-neighbor/knn_documentacao/#exportar-para-as-planilhas","title":"Exportar para as Planilhas","text":"<p>O alto desempenho do modelo (acur\u00e1cia esperada acima de 0.90) demonstra que o <code>Engine Size</code> e a <code>Mileage</code> s\u00e3o preditores fortes para o <code>fuelType</code> dentro do dataset da BMW.</p> output <p><code>python exec=\"on\" html=\"1\" --8&lt;-- \"./docs/k-nearest-neighbor/knn_script.py\"</code></p> code <p><code>python exec=\"off\" --8&lt;-- \"./docs/k-nearest-neighbor/knn_script.py\"</code></p>"},{"location":"k-nearest-neighbor/knn_documentacao/#passo-a-passo-da-implementacao","title":"Passo a Passo da Implementa\u00e7\u00e3o","text":""},{"location":"k-nearest-neighbor/knn_documentacao/#1-importacao-de-bibliotecas-e-carregamento-de-dados","title":"1. Importa\u00e7\u00e3o de Bibliotecas e Carregamento de Dados","text":"<p>Importamos o StandardScaler, que \u00e9 essencial para o algoritmo KNN.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler # CR\u00cdTICO para KNN\nimport seaborn as sns\nimport pandas as pd\nimport kagglehub\n\n# Carregar o dataset\nfile_name = \"bmw.csv\"\ndf = pd.read_csv(file_name) \n\n# Selecionar Features (X) e Vari\u00e1vel Alvo (y)\nX = df[['engineSize', 'mileage']]\ny, fuel_labels = pd.factorize(df['fuelType']) # fuel_labels guarda os nomes das classes\n\n# Limpeza e Prepara\u00e7\u00e3o\ndata = X.copy()\ndata['target'] = y\ndata = data.dropna() \n\nX_clean = data[['engineSize', 'mileage']]\ny_clean = data['target']\n</code></pre>"},{"location":"k-nearest-neighbor/knn_documentacao/#2-escalonamento-dos-atributos-standardscaler","title":"2. Escalonamento dos Atributos (StandardScaler)","text":"<p>O KNN \u00e9 baseado na dist\u00e2ncia. Sem esta etapa, a vari\u00e1vel mileage (valores na casa dos milhares) dominaria o c\u00e1lculo da dist\u00e2ncia em rela\u00e7\u00e3o ao engineSize (valores na casa das unidades), invalidando o modelo.</p> <pre><code># Aplica a Padroniza\u00e7\u00e3o (StandardScaler)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_clean)\nX_scaled_df = pd.DataFrame(X_scaled, columns=X_clean.columns, index=X_clean.index)\n</code></pre>"},{"location":"k-nearest-neighbor/knn_documentacao/#3-treinamento-e-avaliacao-do-modelo","title":"3. Treinamento e Avalia\u00e7\u00e3o do Modelo","text":"<p>Dividimos os dados escalonados (<code>X_scaled_df</code>) e treinamos o <code>KNeighborsClassifier</code> com K=3 vizinhos.</p> <pre><code># Divis\u00e3o Treino/Teste (70% Treino, 30% Teste)\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled_df, y_clean,\n    test_size=0.3,\n    random_state=42\n)\n\n# Treinar o modelo KNN\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\n\n# Prever e Avaliar\npredictions = knn.predict(X_test)\nprint(f\"Accuracy (com escalonamento): {accuracy_score(y_test, predictions):.2f}\")\n</code></pre>"},{"location":"k-nearest-neighbor/knn_documentacao/#4-geracao-da-fronteira-de-decisao","title":"4. Gera\u00e7\u00e3o da Fronteira de Decis\u00e3o","text":"<p>Este passo gera a grade de visualiza\u00e7\u00e3o, garantindo que o labels da legenda seja corretamente convertido para lista para evitar o erro: <code>ValueError: The truth value of a Index is ambiguous</code>.</p> <pre><code>plt.figure(figsize=(12, 10))\n\n# Amostragem para plotagem e defini\u00e7\u00e3o dos limites no espa\u00e7o escalonado\nsample_size = 5000\nX_vis = X_scaled_df.sample(sample_size, random_state=42)\ny_vis = y_clean.loc[X_vis.index]\n\n# Defini\u00e7\u00e3o dos limites da grade (h=0.05 \u00e9 o passo no espa\u00e7o normalizado)\nh = 0.05 \nx_min, x_max = X_scaled_df['engineSize'].min() - 0.5, X_scaled_df['engineSize'].max() + 0.5\ny_min, y_max = X_scaled_df['mileage'].min() - 0.5, X_scaled_df['mileage'].max() + 0.5\n\n# Cria\u00e7\u00e3o da grade e predi\u00e7\u00e3o\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\ngrid_points = np.c_[xx.ravel(), yy.ravel()]\nZ = knn.predict(grid_points).reshape(xx.shape)\n\n# Plot\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu, alpha=0.3)\nsns.scatterplot(x=X_vis['engineSize'], y=X_vis['mileage'], hue=y_vis, style=y_vis,\n                palette=\"deep\", s=100, legend='full')\n\n# Corre\u00e7\u00e3o do Erro: Convers\u00e3o para lista\nhandles, _ = plt.gca().get_legend_handles_labels()\nplt.legend(handles=handles, labels=fuel_labels.tolist(), title=\"Fuel Type\")\n\nplt.xlabel(\"Engine Size (Scaled)\")\nplt.ylabel(\"Mileage (Scaled)\")\nplt.title(\"KNN Decision Boundary (k=3) on Scaled Data\")\n\n# Salva o resultado\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\n# print(buffer.getvalue())\n</code></pre>"},{"location":"k-nearest-neighbor/main/","title":"KNN","text":""},{"location":"k-nearest-neighbor/main/#machine-learning-com-knn-k-nearest-neighbors","title":"Machine Learning com KNN (K-Nearest Neighbors)","text":""},{"location":"k-nearest-neighbor/main/#base-de-dados-utilizada","title":"Base de Dados Utilizada","text":"<p>A base de dados utilizada \u00e9 o conjunto de carros usados da BMW:\\ https://www.kaggle.com/datasets/adityadesai13/used-car-dataset-ford-and-mercedes/data</p>"},{"location":"k-nearest-neighbor/main/#modelo-knn","title":"Modelo KNN","text":"outputcode <p>Accuracy (com escalonamento): 0.67  2025-10-01T17:07:00.061545 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler # Adicionado para escalonamento\nimport seaborn as sns\nimport pandas as pd\nimport kagglehub\n\n# 1. CARREGAMENTO E PR\u00c9-PROCESSAMENTO DE DADOS\n\n# O arquivo foi lido do ambiente de execu\u00e7\u00e3o\npath = kagglehub.dataset_download(\"adityadesai13/used-car-dataset-ford-and-mercedes\")\ndf = pd.read_csv(path + \"/bmw.csv\")\n\n# Selecionar vari\u00e1veis cont\u00ednuas (features)\nX = df[['engineSize', 'mileage']]\n\n# Codificar a vari\u00e1vel alvo 'fuelType'\n# fuel_labels \u00e9 um objeto Index do Pandas\ny, fuel_labels = pd.factorize(df['fuelType'])\n\n# Limpeza dos dados\ndata = X.copy()\ndata['target'] = y\n# O passo dropna() \u00e9 mantido, embora os dados originais (mileage, engineSize) n\u00e3o tivessem nulos\ndata = data.dropna() \n\nX_clean = data[['engineSize', 'mileage']]\ny_clean = data['target']\n\n# 2. ESCALONAMENTO DOS DADOS (CR\u00cdTICO PARA KNN)\nscaler = StandardScaler()\n# Ajustar e transformar as features\nX_scaled = scaler.fit_transform(X_clean)\nX_scaled_df = pd.DataFrame(X_scaled, columns=X_clean.columns, index=X_clean.index)\n\n\n# 3. DIVIS\u00c3O TREINO/TESTE\n# Usamos os dados escalonados (X_scaled_df) para o treino\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled_df, y_clean,\n    test_size=0.3,\n    random_state=42\n)\n\n# 4. TREINAMENTO E AVALIA\u00c7\u00c3O DO MODELO KNN\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy (com escalonamento): {accuracy_score(y_test, predictions):.2f}\")\n\n\n# 5. VISUALIZA\u00c7\u00c3O DA FRONTEIRA DE DECIS\u00c3O\n\n# Reduzir a amostra para visualiza\u00e7\u00e3o (para o scatter plot)\nsample_size = 5000\n# Usamos o \u00edndice para garantir que X_vis e y_vis correspondam\nX_vis = X_scaled_df.sample(sample_size, random_state=42)\ny_vis = y_clean.loc[X_vis.index]\n\nplt.figure(figsize=(12, 10))\n\n# Definir os limites da grade a partir dos dados ESCALONADOS\nh = 0.05 \nx_min, x_max = X_scaled_df['engineSize'].min() - 0.5, X_scaled_df['engineSize'].max() + 0.5\ny_min, y_max = X_scaled_df['mileage'].min() - 0.5, X_scaled_df['mileage'].max() + 0.5\n\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\n# Criar a grade de pontos para predi\u00e7\u00e3o\ngrid_points = np.c_[xx.ravel(), yy.ravel()]\n\n# Previs\u00e3o KNN para cada ponto da grade\nZ = knn.predict(grid_points)\nZ = Z.reshape(xx.shape)\n\n# Plot da fronteira e dos pontos\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu, alpha=0.3)\nsns.scatterplot(x=X_vis['engineSize'], y=X_vis['mileage'], hue=y_vis, style=y_vis,\n                palette=\"deep\", s=100, legend='full')\n\n# Configurar legenda e r\u00f3tulos\nhandles, _ = plt.gca().get_legend_handles_labels()\n\n# CORRE\u00c7\u00c3O DO ERRO: Converter o Index (fuel_labels) para uma lista\nplt.legend(handles=handles, labels=fuel_labels.tolist(), title=\"Fuel Type\")\n\nplt.xlabel(\"Engine Size (Scaled)\")\nplt.ylabel(\"Mileage (Scaled)\")\nplt.title(\"KNN Decision Boundary (k=3) on Scaled Data\")\n\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"k-nearest-neighbor/main/#objetivo-do-projeto","title":"Objetivo do Projeto","text":"<p>O objetivo deste trabalho \u00e9 aplicar o algoritmo K-Nearest Neighbors (KNN) para resolver um problema de Classifica\u00e7\u00e3o e prever o Tipo de Combust\u00edvel (fuelType) de um ve\u00edculo.</p> <p>Para simplificar a visualiza\u00e7\u00e3o da fronteira de decis\u00e3o, o modelo utiliza apenas as seguintes features cont\u00ednuas:</p> <ul> <li>Engine Size (Tamanho do Motor)</li> <li>Mileage (Quilometragem/Rodagem)</li> </ul>"},{"location":"k-nearest-neighbor/main/#analise-e-modelo-knn-k3","title":"An\u00e1lise e Modelo KNN (K=3)","text":"<p>O gr\u00e1fico gerado abaixo representa a fronteira de decis\u00e3o do modelo. As regi\u00f5es coloridas indicam a classe (tipo de combust\u00edvel) que o modelo KNN prev\u00ea para qualquer novo carro que caia naquela \u00e1rea do plano 2D.</p> <p>Tipo de Combust\u00edvel   Cor de Classifica\u00e7\u00e3o</p> <p>Diesel                Azul   Petrol                Vermelho/Laranja   Hybrid                Roxo (\u00e1reas menores)</p>"},{"location":"k-nearest-neighbor/main/#passo-a-passo-da-implementacao","title":"Passo a Passo da Implementa\u00e7\u00e3o","text":""},{"location":"k-nearest-neighbor/main/#1-importacao-de-bibliotecas-e-carregamento-de-dados","title":"1. Importa\u00e7\u00e3o de Bibliotecas e Carregamento de Dados","text":"<p>Importamos o StandardScaler, que \u00e9 essencial para o algoritmo KNN.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler # CR\u00cdTICO para KNN\nimport seaborn as sns\nimport pandas as pd\nimport kagglehub\n\n# Carregar o dataset\nfile_name = \"bmw.csv\"\ndf = pd.read_csv(file_name) \n\n# Selecionar Features (X) e Vari\u00e1vel Alvo (y)\nX = df[['engineSize', 'mileage']]\ny, fuel_labels = pd.factorize(df['fuelType']) # fuel_labels guarda os nomes das classes\n\n# Limpeza e Prepara\u00e7\u00e3o\ndata = X.copy()\ndata['target'] = y\ndata = data.dropna() \n\nX_clean = data[['engineSize', 'mileage']]\ny_clean = data['target']\n</code></pre>"},{"location":"k-nearest-neighbor/main/#2-escalonamento-dos-atributos-standardscaler","title":"2. Escalonamento dos Atributos (StandardScaler)","text":"<p>O KNN \u00e9 baseado na dist\u00e2ncia. Sem esta etapa, a vari\u00e1vel mileage (valores na casa dos milhares) dominaria o c\u00e1lculo da dist\u00e2ncia em rela\u00e7\u00e3o ao engineSize (valores na casa das unidades), invalidando o modelo.</p> <pre><code># Aplica a Padroniza\u00e7\u00e3o (StandardScaler)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_clean)\nX_scaled_df = pd.DataFrame(X_scaled, columns=X_clean.columns, index=X_clean.index)\n</code></pre>"},{"location":"k-nearest-neighbor/main/#3-treinamento-e-avaliacao-do-modelo","title":"3. Treinamento e Avalia\u00e7\u00e3o do Modelo","text":"<p>Dividimos os dados escalonados (<code>X_scaled_df</code>) e treinamos o <code>KNeighborsClassifier</code> com K=3 vizinhos.</p> <pre><code># Divis\u00e3o Treino/Teste (70% Treino, 30% Teste)\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled_df, y_clean,\n    test_size=0.3,\n    random_state=42\n)\n\n# Treinar o modelo KNN\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\n\n# Prever e Avaliar\npredictions = knn.predict(X_test)\nprint(f\"Accuracy (com escalonamento): {accuracy_score(y_test, predictions):.2f}\")\n</code></pre>"},{"location":"k-nearest-neighbor/main/#4-geracao-da-fronteira-de-decisao","title":"4. Gera\u00e7\u00e3o da Fronteira de Decis\u00e3o","text":"<p>Este passo gera a grade de visualiza\u00e7\u00e3o, garantindo que o labels da legenda seja corretamente convertido para lista para evitar o erro: <code>ValueError: The truth value of a Index is ambiguous</code>.</p> <pre><code>plt.figure(figsize=(12, 10))\n\n# Amostragem para plotagem e defini\u00e7\u00e3o dos limites no espa\u00e7o escalonado\nsample_size = 5000\nX_vis = X_scaled_df.sample(sample_size, random_state=42)\ny_vis = y_clean.loc[X_vis.index]\n\n# Defini\u00e7\u00e3o dos limites da grade (h=0.05 \u00e9 o passo no espa\u00e7o normalizado)\nh = 0.05 \nx_min, x_max = X_scaled_df['engineSize'].min() - 0.5, X_scaled_df['engineSize'].max() + 0.5\ny_min, y_max = X_scaled_df['mileage'].min() - 0.5, X_scaled_df['mileage'].max() + 0.5\n\n# Cria\u00e7\u00e3o da grade e predi\u00e7\u00e3o\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\ngrid_points = np.c_[xx.ravel(), yy.ravel()]\nZ = knn.predict(grid_points).reshape(xx.shape)\n\n# Plot\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu, alpha=0.3)\nsns.scatterplot(x=X_vis['engineSize'], y=X_vis['mileage'], hue=y_vis, style=y_vis,\n                palette=\"deep\", s=100, legend='full')\n\n# Corre\u00e7\u00e3o do Erro: Convers\u00e3o para lista\nhandles, _ = plt.gca().get_legend_handles_labels()\nplt.legend(handles=handles, labels=fuel_labels.tolist(), title=\"Fuel Type\")\n\nplt.xlabel(\"Engine Size (Scaled)\")\nplt.ylabel(\"Mileage (Scaled)\")\nplt.title(\"KNN Decision Boundary (k=3) on Scaled Data\")\n\n# Salva o resultado\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\n# print(buffer.getvalue())\n</code></pre>"},{"location":"metrics/main/","title":"Metrics","text":"outputcode <p>Acur\u00e1cia (Accuracy): 0.8156  Matriz de Confus\u00e3o: [[92 13]  [20 54]]  Relat\u00f3rio de Classifica\u00e7\u00e3o (Precision, Recall, F1-Score):               precision    recall  f1-score   support             0       0.82      0.88      0.85       105            1       0.81      0.73      0.77        74      accuracy                           0.82       179    macro avg       0.81      0.80      0.81       179 weighted avg       0.82      0.82      0.81       179   2025-10-01T17:07:01.104085 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ </p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import BytesIO # Importa\u00e7\u00e3o para a sa\u00edda de gr\u00e1fico em SVG\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport kagglehub\nimport os\n\n# 1. EXPLORA\u00c7\u00c3O E PREPARA\u00c7\u00c3O DOS DADOS\n# Carrega o arquivo 'Titanic-Dataset.csv'\npath = kagglehub.dataset_download(\"yasserh/titanic-dataset\")\nfile_path = os.path.join(path, \"Titanic-Dataset.csv\")\ndf = pd.read_csv(file_path)\n\n# Defini\u00e7\u00e3o das Features e do Target\nfeatures = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\ntarget = 'Survived'\n\nX = df[features]\ny = df[target]\n\n# 2. PR\u00c9-PROCESSAMENTO AVAN\u00c7ADO (Pipeline)\nnumerical_features = ['Age', 'Fare', 'SibSp', 'Parch']\ncategorical_features = ['Pclass', 'Sex', 'Embarked'] \n\n# Pipeline para features Num\u00e9ricas: Imputa\u00e7\u00e3o (mediana) + Escalonamento (StandardScaler)\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler()) # CRUCIAL para KNN\n])\n\n# Pipeline para features Categ\u00f3ricas: Imputa\u00e7\u00e3o (mais frequente) + One-Hot Encoding\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# ColumnTransformer combina os pipelines de pr\u00e9-processamento\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_features),\n        ('cat', categorical_transformer, categorical_features)\n    ],\n    remainder='passthrough'\n)\n\n# 3. DIVIS\u00c3O DOS DADOS\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 4. TREINAMENTO DO MODELO (KNN)\n# Pipeline completo: Pr\u00e9-processador + Classificador KNN (k=5)\nknn_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', KNeighborsClassifier(n_neighbors=5)) \n])\n\nknn_pipeline.fit(X_train, y_train)\n\n# 5. AVALIA\u00c7\u00c3O DO MODELO\ny_pred = knn_pipeline.predict(X_test)\n\n# M\u00e9tricas de Desempenho\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\nprint(f\"Acur\u00e1cia (Accuracy): {accuracy:.4f}\")\nprint(\"\\nMatriz de Confus\u00e3o:\")\nprint(conf_matrix)\nprint(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o (Precision, Recall, F1-Score):\")\nprint(class_report)\n\n# Gera o gr\u00e1fico da Matriz de Confus\u00e3o\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['N\u00e3o Sobreviveu (0)', 'Sobreviveu (1)'],\n            yticklabels=['N\u00e3o Sobreviveu (0)', 'Sobreviveu (1)'])\nplt.ylabel('Valor Verdadeiro')\nplt.xlabel('Predi\u00e7\u00e3o')\nplt.title('Matriz de Confus\u00e3o do KNN (k=5)')\n\n# SALVA O GR\u00c1FICO NO BUFFER E IMPRIME O CONTE\u00daDO SVG\nbuffer = BytesIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nbuffer.seek(0)\nprint(buffer.getvalue().decode(\"utf-8\"))\n</code></pre>"},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p> <p>RMSE: 19847.42 R\u00b2: 0.860  2025-10-01T17:07:01.915624 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ </p>"}]}